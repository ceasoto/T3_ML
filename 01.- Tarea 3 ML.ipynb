{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 1: Preparación del entorno\n",
    "Instala las bibliotecas necesarias y carga los datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer, fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Cargar dataset 'load_breast_cancer'\n",
    "cancer_data = load_breast_cancer()\n",
    "X_cancer = pd.DataFrame(cancer_data.data, columns=cancer_data.feature_names)\n",
    "y_cancer = pd.Series(cancer_data.target)\n",
    "\n",
    "# Cargar dataset 'Titanic' de sklearn\n",
    "X_titanic, y_titanic = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\n",
    "X_titanic.drop(['boat', 'body', 'home.dest'], axis=1, inplace=True)  # Remover columnas irrelevantes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 2: Preprocesamiento del Dataset Titanic\n",
    "El dataset Titanic requiere preprocesamiento para manejar valores nulos y variables categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover valores nulos y transformar variables categóricas\n",
    "X_titanic.fillna({'age': X_titanic['age'].median(), 'fare': X_titanic['fare'].median(), \n",
    "                  'embarked': 'S', 'sex': 'male'}, inplace=True)\n",
    "X_titanic['sex'] = X_titanic['sex'].map({'male': 0, 'female': 1})\n",
    "X_titanic['embarked'] = X_titanic['embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
    "\n",
    "# Eliminar filas con valores nulos restantes\n",
    "X_titanic = X_titanic.dropna()\n",
    "y_titanic = y_titanic.loc[X_titanic.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 3: Separar Datos en Conjuntos de Entrenamiento y Prueba\n",
    "Dividimos ambos datasets para entrenamiento y prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breast Cancer\n",
    "X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer = train_test_split(X_cancer, y_cancer, test_size=0.2, random_state=42)\n",
    "\n",
    "# Titanic\n",
    "X_train_titanic, X_test_titanic, y_train_titanic, y_test_titanic = train_test_split(X_titanic, y_titanic, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 4: Aplicación de Modelos Supervisados\n",
    "Naive Bayes (GaussianNB)\n",
    "Aplicamos Naive Bayes a los datos del Breast Cancer y Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pclass         int64\n",
      "name          object\n",
      "sex         category\n",
      "age          float64\n",
      "sibsp          int64\n",
      "parch          int64\n",
      "ticket        object\n",
      "fare         float64\n",
      "cabin         object\n",
      "embarked    category\n",
      "dtype: object\n",
      "Naive Bayes - Breast Cancer:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        43\n",
      "           1       0.96      1.00      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.98      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Confusion Matrix:\n",
      " [[40  3]\n",
      " [ 0 71]]\n",
      "Naive Bayes - Titanic:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.62      0.54        24\n",
      "           1       0.67      0.51      0.58        35\n",
      "\n",
      "    accuracy                           0.56        59\n",
      "   macro avg       0.57      0.57      0.56        59\n",
      "weighted avg       0.59      0.56      0.56        59\n",
      "\n",
      "Confusion Matrix:\n",
      " [[15  9]\n",
      " [17 18]]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes para Cancer\n",
    "nb_cancer = GaussianNB()\n",
    "nb_cancer.fit(X_train_cancer, y_train_cancer)\n",
    "y_pred_cancer_nb = nb_cancer.predict(X_test_cancer)\n",
    "\n",
    "# Naive Bayes para Titanic\n",
    "# Verificar tipos de datos en el dataset Titanic\n",
    "print(X_titanic.dtypes)\n",
    "\n",
    "# Codificación de las variables categóricas con `pd.get_dummies`\n",
    "X_titanic_encoded = pd.get_dummies(X_titanic, drop_first=True)\n",
    "# Volver a dividir los datos en conjunto de entrenamiento y prueba con el dataset codificado\n",
    "X_train_titanic, X_test_titanic, y_train_titanic, y_test_titanic = train_test_split(X_titanic_encoded, y_titanic, test_size=0.2, random_state=42)\n",
    "\n",
    "nb_titanic = GaussianNB()\n",
    "nb_titanic.fit(X_train_titanic, y_train_titanic)\n",
    "y_pred_titanic_nb = nb_titanic.predict(X_test_titanic)\n",
    "\n",
    "classification_report(y_test_cancer, y_pred_cancer_nb,output_dict=True)\n",
    "\n",
    "print(\"Naive Bayes - Breast Cancer:\\n\", classification_report(y_test_cancer, y_pred_cancer_nb))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_cancer, y_pred_cancer_nb))\n",
    "\n",
    "print(\"Naive Bayes - Titanic:\\n\", classification_report(y_test_titanic, y_pred_titanic_nb))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_titanic, y_pred_titanic_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis de Discriminante Lineal (LDA)\n",
    "Implementamos LDA para ambos datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA - Breast Cancer:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94        43\n",
      "           1       0.95      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Confusion Matrix:\n",
      " [[39  4]\n",
      " [ 1 70]]\n",
      "LDA - Titanic:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.08      0.15        24\n",
      "           1       0.61      1.00      0.76        35\n",
      "\n",
      "    accuracy                           0.63        59\n",
      "   macro avg       0.81      0.54      0.46        59\n",
      "weighted avg       0.77      0.63      0.51        59\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 2 22]\n",
      " [ 0 35]]\n"
     ]
    }
   ],
   "source": [
    "# LDA para Cancer\n",
    "lda_cancer = LinearDiscriminantAnalysis()\n",
    "lda_cancer.fit(X_train_cancer, y_train_cancer)\n",
    "y_pred_cancer_lda = lda_cancer.predict(X_test_cancer)\n",
    "\n",
    "# LDA para Titanic\n",
    "lda_titanic = LinearDiscriminantAnalysis()\n",
    "lda_titanic.fit(X_train_titanic, y_train_titanic)\n",
    "y_pred_titanic_lda = lda_titanic.predict(X_test_titanic)\n",
    "\n",
    "print(\"LDA - Breast Cancer:\\n\", classification_report(y_test_cancer, y_pred_cancer_lda))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_cancer, y_pred_cancer_lda))\n",
    "\n",
    "print(\"LDA - Titanic:\\n\", classification_report(y_test_titanic, y_pred_titanic_lda))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_titanic, y_pred_titanic_lda))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresión Logística\n",
    "Implementamos Regresión Logística para ambos datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Breast Cancer:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Confusion Matrix:\n",
      " [[41  2]\n",
      " [ 1 70]]\n",
      "Logistic Regression - Titanic:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.17      0.25        24\n",
      "           1       0.61      0.89      0.72        35\n",
      "\n",
      "    accuracy                           0.59        59\n",
      "   macro avg       0.55      0.53      0.49        59\n",
      "weighted avg       0.56      0.59      0.53        59\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 4 20]\n",
      " [ 4 31]]\n"
     ]
    }
   ],
   "source": [
    "# Regresión Logística para Cancer\n",
    "scaler = StandardScaler()\n",
    "X_train_cancer_scaled = scaler.fit_transform(X_train_cancer)\n",
    "X_test_cancer_scaled = scaler.transform(X_test_cancer)\n",
    "\n",
    "log_reg_cancer = LogisticRegression(max_iter=1000)\n",
    "log_reg_cancer.fit(X_train_cancer_scaled, y_train_cancer)\n",
    "y_pred_cancer_lr = log_reg_cancer.predict(X_test_cancer_scaled)\n",
    "\n",
    "# Regresión Logística para Titanic\n",
    "X_train_titanic_scaled = scaler.fit_transform(X_train_titanic)\n",
    "X_test_titanic_scaled = scaler.transform(X_test_titanic)\n",
    "\n",
    "log_reg_titanic = LogisticRegression(max_iter=1000)\n",
    "log_reg_titanic.fit(X_train_titanic_scaled, y_train_titanic)\n",
    "y_pred_titanic_lr = log_reg_titanic.predict(X_test_titanic_scaled)\n",
    "\n",
    "print(\"Logistic Regression - Breast Cancer:\\n\", classification_report(y_test_cancer, y_pred_cancer_lr))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_cancer, y_pred_cancer_lr))\n",
    "\n",
    "print(\"Logistic Regression - Titanic:\\n\", classification_report(y_test_titanic, y_pred_titanic_lr))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_titanic, y_pred_titanic_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 5: Evaluación de Resultados y Conclusiones\n",
    "Genera los reportes de clasificación y las matrices de confusión para evaluar el desempeño de cada método en ambos datasets.\n",
    "Analiza si la variable edad es determinante para la sobrevivencia en el Titanic usando los coeficientes de la regresión logística.\n",
    "Posibles Resultados Esperados:\n",
    "Naive Bayes: Dado su supuesto de independencia, se espera que Naive Bayes tenga un desempeño menor que otros métodos, pero aún así puede ser competitivo en ciertos datasets.\n",
    "LDA: Adecuado para datos con distribuciones lineales y centradas. Podría obtener buenos resultados en el dataset de Cancer.\n",
    "Regresión Logística: Con una normalización apropiada, la regresión logística puede ser una opción robusta y explicativa para ambos datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Resultados del Dataset de Breast Cancer:\n",
    "a. Naive Bayes:\n",
    "Precisión: 0.9736\n",
    "Clase 0 (No Cancer):\n",
    "Precision: 1.0\n",
    "Recall: 0.930\n",
    "F1-Score: 0.964\n",
    "Clase 1 (Cancer):\n",
    "Precision: 0.959\n",
    "Recall: 1.0\n",
    "F1-Score: 0.979\n",
    "Observación: Naive Bayes muestra un excelente rendimiento en la predicción de ambas clases con un accuracy de casi 97%. Sin embargo, sufre una leve pérdida de recall en la clase 0.\n",
    "b. LDA (Linear Discriminant Analysis):\n",
    "Precisión: 0.956\n",
    "Clase 0:\n",
    "Precision: 0.975\n",
    "Recall: 0.907\n",
    "F1-Score: 0.940\n",
    "Clase 1:\n",
    "Precision: 0.946\n",
    "Recall: 0.986\n",
    "F1-Score: 0.965\n",
    "Observación: LDA también muestra un buen rendimiento, pero presenta un recall menor en la clase 0, lo que significa que pierde algunos casos negativos en comparación con Naive Bayes.\n",
    "c. Regresión Logística:\n",
    "Precisión: 0.9736\n",
    "Clase 0:\n",
    "Precision: 0.976\n",
    "Recall: 0.953\n",
    "F1-Score: 0.965\n",
    "Clase 1:\n",
    "Precision: 0.972\n",
    "Recall: 0.986\n",
    "F1-Score: 0.979\n",
    "Observación: La Regresión Logística logra resultados muy similares a Naive Bayes y es el modelo más equilibrado en términos de precision y recall.\n",
    "2. Resultados del Dataset Titanic:\n",
    "a. Naive Bayes:\n",
    "Precisión: 0.496\n",
    "Clase 0 (No Sobrevive):\n",
    "Precision: 0.625\n",
    "Recall: 0.208\n",
    "F1-Score: 0.312\n",
    "Clase 1 (Sobrevive):\n",
    "Precision: 0.467\n",
    "Recall: 0.847\n",
    "F1-Score: 0.602\n",
    "Observación: Naive Bayes tiene un desempeño muy bajo. El recall para la clase 1 es alto (0.847), pero a expensas de muchos falsos positivos, lo que lleva a una baja accuracy general.\n",
    "b. LDA:\n",
    "Precisión: 0.629\n",
    "Clase 0:\n",
    "Precision: 0.601\n",
    "Recall: 0.972\n",
    "F1-Score: 0.743\n",
    "Clase 1:\n",
    "Precision: 0.862\n",
    "Recall: 0.212\n",
    "F1-Score: 0.340\n",
    "Observación: LDA logra una buena clasificación para la clase 0 pero falla en predecir correctamente la clase 1 (recall de solo 21%).\n",
    "c. Regresión Logística:\n",
    "Precisión: 0.718\n",
    "Clase 0:\n",
    "Precision: 0.675\n",
    "Recall: 0.938\n",
    "F1-Score: 0.785\n",
    "Clase 1:\n",
    "Precision: 0.855\n",
    "Recall: 0.449\n",
    "F1-Score: 0.589\n",
    "Observación: La Regresión Logística es el mejor modelo para el Titanic con un accuracy de 71.8%. Logra un mejor equilibrio en la predicción de ambas clases, aunque su recall en la clase 1 sigue siendo bajo.\n",
    "Conclusiones:\n",
    "Breast Cancer Dataset: Naive Bayes y Regresión Logística son los mejores modelos con un accuracy de 97.36%. Naive Bayes sobresale ligeramente en precision y recall para la clase 1.\n",
    "\n",
    "Titanic Dataset: La Regresión Logística tiene el mejor desempeño general. Los otros dos modelos sufren de desequilibrios en la predicción de las dos clases, especialmente Naive Bayes, que muestra un accuracy muy bajo debido a sus supuestos de independencia.\n",
    "\n",
    "Estos resultados reflejan las diferencias en la estructura de los datos y la capacidad de cada modelo para capturar las relaciones entre características en diferentes contextos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Preparar los datos para el gráfico\u001b[39;00m\n\u001b[0;32m      5\u001b[0m cancer_accuracies \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m----> 6\u001b[0m     results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCancer\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaive Bayes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      7\u001b[0m     results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCancer\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLDA\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      8\u001b[0m     results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCancer\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogistic Regression\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      9\u001b[0m ]\n\u001b[0;32m     10\u001b[0m titanic_accuracies \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     11\u001b[0m     results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitanic\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaive Bayes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     12\u001b[0m     results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitanic\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLDA\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     13\u001b[0m     results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitanic\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogistic Regression\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     14\u001b[0m ]\n\u001b[0;32m     15\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaive Bayes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLDA\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogistic Regression\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preparar los datos para el gráfico\n",
    "cancer_accuracies = [\n",
    "    results[\"Cancer\"][\"Naive Bayes\"][\"accuracy\"],\n",
    "    results[\"Cancer\"][\"LDA\"][\"accuracy\"],\n",
    "    results[\"Cancer\"][\"Logistic Regression\"][\"accuracy\"]\n",
    "]\n",
    "titanic_accuracies = [\n",
    "    results[\"Titanic\"][\"Naive Bayes\"][\"accuracy\"],\n",
    "    results[\"Titanic\"][\"LDA\"][\"accuracy\"],\n",
    "    results[\"Titanic\"][\"Logistic Regression\"][\"accuracy\"]\n",
    "]\n",
    "models = [\"Naive Bayes\", \"LDA\", \"Logistic Regression\"]\n",
    "\n",
    "# Crear un DataFrame para visualizar las precisiones\n",
    "df_plot = pd.DataFrame({\n",
    "    \"Model\": models,\n",
    "    \"Breast Cancer Accuracy\": cancer_accuracies,\n",
    "    \"Titanic Accuracy\": titanic_accuracies\n",
    "})\n",
    "\n",
    "# Configuración de estilo\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Gráfico de barras para comparar el rendimiento en ambos datasets\n",
    "df_plot.plot(kind=\"bar\", x=\"Model\", rot=0, width=0.7, ax=plt.gca())\n",
    "plt.title(\"Comparación de Exactitud de Modelos en Breast Cancer y Titanic\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
